import os
import openai
import json
from unidecode import unidecode
from dotenv import load_dotenv
from docx import Document
from docx.shared import Inches
from PyPDF2 import PdfReader
import asyncio
import tracemalloc

tracemalloc.start()

# Cargar las variables de entorno desde el archivo .env
load_dotenv()

# Importar la clave de la API de OpenAI desde el archivo .env
api_key = os.getenv("OPENAI_API_KEY")
openai.api_key = api_key

index = []  # [{chapter_name: [subchapter_1, subchapter_2, ...], number_of_pages:4, chapter_summary:"Summary of the chapter", generated_summary:"Summary generated by GPT"}, ...]
project_summary = ""

project_name = ""
project_context = ""

type_of_project = "" # "thesis", "syllabus", "works"
style_of_writing = ""
project_guideline_summary = ""

thesis_context = "Estoy asistiendo en la elaboración de trabajos de fin de grado y fin de máster en español de España. Los documentos serán en formato markdown.  Debes desarrollar el contenido de forma extensa, ahondando en la temática y explicando detalladamente los conceptos. Aunque no se proporcionen detalles específicos, el modelo debe ser capaz de generar contenido basado en situaciones que son comunes en este tipo de trabajos académicos. Se permite inventar información que, aunque no haya sucedido, es plausible y común en el contexto académico. Centra la redacción en desarrollar de forma extensa el tema y sus subapartados, sin incluir una sección de conclusión o frases del tipo 'En resumen...'."
syllabus_context = f"Estoy realizando la elaboración de un temario titulado {project_name} y me estás ayudando a redactarlo"
work_context = f"Estoy realizando la elaboración de un trabajo titulado {project_name} y me estás ayudando a redactarlo"


def generate_chapter_prompt(chapter_name, summary, subchapters, number_of_pages=1):
    global type_of_project
    if type_of_project == "papers":
        return generate_chapter_paper_prompt(chapter_name, summary, number_of_pages, subchapters)
    elif type_of_project == "syllabus":
        return generate_chapter_syllabus_prompt(chapter_name, summary, number_of_pages, subchapters)
    elif type_of_project == "works":
        return generate_work_prompt(chapter_name, summary, number_of_pages, subchapters)


def generate_chapter_paper_prompt(chapter_name, summary, number_of_pages, subchapters):
    return f'{thesis_context} Escribe un capítulo sobre {chapter_name}. Que trate de {summary}. Y tenga una extensión de {number_of_pages * int(os.getenv("WORDS_FOR_PAGE"))} palabras. {add_subchapters_to_prompt(subchapters)} {add_style_of_writing_to_prompt()}'


def generate_chapter_syllabus_prompt(chapter_name, summary, number_of_pages, subchapters):
    return f'Escribe un capítulo sobre {chapter_name}. Que trate de {summary}. Y tenga una extensión de {number_of_pages * int(os.getenv("WORDS_FOR_PAGE"))} palabras. {add_subchapters_to_prompt(subchapters)} {add_style_of_writing_to_prompt()}'


def generate_work_prompt(chapter_name, summary, number_of_pages, subchapters):
    return f'Escribe un capítulo sobre {chapter_name}. Que trate de {summary}. Y tenga una extensión de {number_of_pages * int(os.getenv("WORDS_FOR_PAGE"))} palabras. {add_subchapters_to_prompt(subchapters)} {add_style_of_writing_to_prompt()}'


def add_style_of_writing_to_prompt():
    global style_of_writing
    add_style_of_writing_prompt = ""
    if style_of_writing != "":
        add_style_of_writing_prompt = f'"Basándote en el bloque de texto entre tres signos de dólar, imita el estilo de escritura del autor original. Asegúrate de mantener los siguientes aspectos del estilo del autor: Longitud y complejidad de las oraciones. Tono general (formal, informal, humorístico, serio, etc.). Tipos de puntuación utilizados (elipsis, exclamaciones, etc.). Organización de ideas y argumentos. Por favor, intenta que la similitud en el estilo de escritura sea lo más precisa posible.$$${style_of_writing}$$$'
    return add_style_of_writing_prompt


def add_subchapters_to_prompt(subchapters):
    if subchapters.__len__() > 0:
        return f"El capítulo se divide en los siguientes subcapítulos: {subchapters}."
    else:
        return ""


def text_analysis_prompt(text_to_analyze):
    return f'Por favor, analiza el siguiente bloque de texto que se encuentra entre tres comillas dobles que representa el estilo de escritura de un autor específico. Toma en cuenta elementos como la estructura de las oraciones, el uso de vocabulario, la puntuación, y el tono general. Una vez que hayas analizado estos elementos, genera una respuesta de aproximadamente 50 a 100 palabras sobre un tema distinto al texto original. Asegúrate de que tu respuesta mantenga y refleje el estilo de escritura del autor inicial en la medida de lo posible. Además, intenta incorporar los siguientes aspectos del estilo original: Si el texto original utiliza frases largas y complejas, haz lo mismo en tu respuesta. Mantén el tono del texto original, ya sea formal, informal, humorístico, serio, etc. Si el texto original hace uso frecuente de ciertos tipos de puntuación (como elipsis, exclamaciones, etc.), intenta incorporarlos en tu respuesta. Observa cómo el autor organiza sus ideas y argumentos, e intenta replicar esa estructura en tu respuesta.'f'"""{text_to_analyze}"""'


def generate_index_prompt(project_info):
    return 'Necesito que de este texto entre tres comillas dobles donde se pide la realización de un proyecto se devuelvas un objeto json con el siguiente formato: { summary : "resumen del texto del proyecto que se desea realizar", proposed_index : [{chapter_name: [subchapter_1, subchapter_2, ...], number_of_pages:x, chapter_summary:"Summary of the chapter", ...] } """' + project_info + '"""'


class Chapter:
    def __init__(self, chapter_name, number_of_pages, chapter_summary, generated_summary, subchapters):
        self.chapter_name = chapter_name
        self.number_of_pages = number_of_pages
        self.chapter_summary = chapter_summary
        self.generated_summary = generated_summary
        self.subchapters = subchapters

    @staticmethod
    def chapters_from_json_array(json_array):
        chapters = []
        for json_dict in json_array:
            chapters.append(Chapter(
                json_dict['chapter_name'],
                json_dict['number_of_pages'],
                json_dict['chapter_summary'],
                json_dict['generated_summary'] if json_dict.get('generated_summary') is not None else "",
                json_dict['subchapters'] if json_dict.get('subchapters') is not None else []
            ))
        return chapters


async def generate_chapter(chapter, add_context=True, model=os.getenv("MODEL_GPT_CHAPTER_GENERATION"),
                           max_tokens=os.getenv("MAX_TOKENS_GPT_CHAPTER_GENERATION")):
    global project_context
    messages = [
        {"role": "system",
         "content": "Este espacio está dedicado a la generación de capítulos de texto con parámetros específicos."},
        {"role": "user", "content": project_context},
        {"role": "user", "content": generate_chapter_prompt(chapter.chapter_name, chapter.chapter_summary,
                                                                  chapter.subchapters, chapter.number_of_pages)}]

    content_generated = False
    chapter_summary = ""
    while not content_generated:
        try:
            response = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                max_tokens=int(max_tokens),
                n=1,
                stop=None,
                temperature=float(os.getenv("TEMPERATURE_GPT_CHAPTER_GENERATION")),
            )
            content_generated = True
            chapter_generated = response.choices[0].message["content"]
            chapter_summary = summarize_chapter(chapter, chapter_generated)
        except Exception as e:
            print(f"Error en la generación del capítulo, volviendo a intentar... {e}")

    print(f'Capítulo: {chapter.chapter_name}\n{chapter_generated}\n\n Contexto actual: {project_context}\n\n')
    return chapter_generated, chapter_summary


def summarize_chapter(chapter, content, model="gpt-3.5-turbo", max_tokens=700):
    global project_context

    messages = [
        {"role": "system",
         "content": "Este es un espacio destinado para la generación de resúmenes concisos de capítulos. Al proporcionar el texto de un capítulo, el asistente producirá un resumen de menos de 60 palabras que captura los puntos más importantes del material. Por favor, asegúrate de que el texto del capítulo sea claro para permitir un resumen preciso."},
        {"role": "user", "content": "Haz un resumen de este capítulo de menos de 60 palabras: " + content}]

    content_generated = False

    while not content_generated:
        try:
            response = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                n=1,
                stop=None,
                temperature=0,  # this is the degree of randomness of the model's output
            )
            content_generated = True
            return f"El capítulo {chapter} trata sobre {response.choices[0].message['content']}"
        except Exception as e:
            print(f"Error en la generación del resumen, volviendo a intentar... {e}")

    return ""


def gpt_text_analysis(text, model=os.getenv("MODEL_GPT_TEXT_ANALYSIS"), max_tokens=700):
    messages = [
        {"role": "system",
         "content": "Este es un espacio para el análisis de estilo de escritura. Al ingresar un bloque de texto para análisis, el asistente evaluará varios elementos como la estructura de las oraciones, el uso de vocabulario, la puntuación y el tono. Posteriormente, se generará una respuesta que intente imitar el estilo del texto original. Por favor, sigue las instrucciones detalladas para obtener los mejores resultados."},
        {"role": "user", "content": text_analysis_prompt(text)}]

    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        max_tokens=max_tokens,
        n=1,
        stop=None,
        temperature=float(os.getenv("TEMPERATURE_GPT_TEXT_ANALYSIS")),
    )
    print(response.choices[0].message["content"])
    return response.choices[0].message["content"]


def gpt_index_generation(project_info, model=os.getenv("MODEL_GPT_INDEX_GENERATION"), max_tokens=1000):
    messages = [
        {"role": "system",
         "content": "Este es un espacio diseñado para la conversión de descripciones de proyectos en un formato de objeto JSON estructurado. Al enviar un texto de proyecto entre comillas triples, el asistente interpretará el contenido y generará un objeto JSON que incluirá un resumen del proyecto, un índice propuesto con nombres de capítulos, subcapítulos y número de páginas, además de resúmenes para cada capítulo. Por favor, sigue las pautas específicas para garantizar una conversión precisa."},
        {"role": "user", "content": generate_index_prompt(project_info)}]

    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        max_tokens=max_tokens,
        n=1,
        stop=None,
        temperature=float(os.getenv("TEMPERATURE_GPT_INDEX_GENERATION")),
    )
    print(response.choices[0].message["content"])
    return response.choices[0].message["content"]


def set_general_project_info():
    global project_name
    project_name = input("Introduce el título del proyecto: ")


async def generate_project():
    global index
    global type_of_project
    os.makedirs(f"generated/{type_of_project}/{project_name}", exist_ok=True)

    for chapter in index:
        if os.path.exists(f"generated/{type_of_project}/{project_name}/{chapter}.md"):
            if delete_file_with_confirmation(f"generated/{type_of_project}/{project_name}/{chapter.chapter_name}.md"):
                content, summary = generate_chapter(chapter)
                write_new_chapter(chapter, content)
        else:
            content, summary = await generate_chapter(chapter)
            write_new_chapter(chapter, content)


def add_summarized_chapter_to_index_and_save(chapter_name, summary):
    global index
    global project_guideline_summary
    for chapter in index:
        if chapter.chapter_name == chapter_name:
            chapter.generated_summary = summary
    print(f"Índice actualizado: {index}")
    save_project_summary_in_json({"summary": project_guideline_summary, "proposed_index": index})


def write_new_chapter(chapter_name, content):
    global type_of_project
    filename = f"generated/{type_of_project}/{project_name}/{chapter_name}.md"
    write_new_file(filename, content)


def confirm_deleting_file():
    confirm = input("¿Estás seguro de que quieres borrar el archivo? (s/n): ")
    while confirm not in ["s", "n"]:
        confirm = input("Por favor, introduce una opción válida: ")
    return confirm == "s"


def delete_file_with_confirmation(filename):
    delete_file_confirmation = confirm_deleting_file()
    if delete_file_confirmation:
        os.remove(filename)
        print("Archivo borrado correctamente")
    else:
        print("Archivo no borrado")
    return delete_file_confirmation


def write_new_file(filename, content):
    if_file_exists_delete(filename)
    with open(filename, "w") as file:
        file.write(content)


def if_file_exists_delete(filename):
    if os.path.exists(filename):
        os.remove(filename)


def select_project_type():
    global type_of_project
    type_of_project_selection = input(
        "¿Qué tipo de proyecto quieres generar? (1) Trabajo fin de estudios, (2) Temario ,(3) Trabajo estándar: ")
    while type_of_project_selection not in ["1", "2", "3"]:
        type_of_project_selection = input("Por favor, introduce un número válido: ")
    if type_of_project_selection == "1":
        type_of_project = "thesis"
    if type_of_project_selection == "2":
        type_of_project = "syllabus"
    if type_of_project_selection == "3":
        type_of_project = "works"


def set_style_of_writing():
    global style_of_writing
    style_of_writing = input(
        "¿Qué tipo de estilo de escritura quieres generar? (1) Formal, (2) Personalizado (debes cargar un PDF), (3) Carga un estilo anterior: ")
    while style_of_writing not in ["1", "2", "3"]:
        style_of_writing = input("Por favor, introduce un número válido: ")
    if style_of_writing == "2":
        set_style_of_writing_from_pdf()
    elif style_of_writing == "3":
        load_style_of_writing()


def set_style_of_writing_from_pdf():
    global style_of_writing
    pdf_route = input("Introduce la ruta del PDF: ")
    while not os.path.exists(pdf_route):
        pdf_route = input("Por favor, introduce una ruta válida: ")
    document_text = PdfReader(pdf_route).pages[
        int(len(PdfReader(pdf_route).pages) / 2)].extract_text()
    style_of_writing = gpt_text_analysis(document_text)
    save_style_of_writing_confirmation()


def save_style_of_writing_confirmation():
    save_style = input("¿Quieres guardar el estilo de escritura? (s/n): ")
    while save_style not in ["s", "n"]:
        save_style = input("Por favor, introduce una opción válida: ")
    if save_style == "s":
        save_style_of_writing()


def save_style_of_writing():
    global style_of_writing
    style_of_writing_name = input("Introduce el nombre del estilo: ")
    while style_of_writing_name == "":
        style_of_writing_name = input("Por favor, introduce un nombre válido: ")
    write_new_file(f"data/styles_of_writing/{style_of_writing_name}", style_of_writing)


def load_style_of_writing():
    global style_of_writing
    print("Estilos de escritura disponibles: ")
    list_of_writing_styles = os.listdir("data/styles_of_writing")
    for file_name in list_of_writing_styles:
        print(file_name)
    style_of_writing_name = input("Introduce el nombre del estilo: ")
    while style_of_writing_name not in list_of_writing_styles:
        style_of_writing_name = input("Por favor, introduce un nombre válido: ")
    style_of_writing = open(f"data/styles_of_writing/{style_of_writing_name}", "r").read()
    print(f"Estilo de escritura cargado correctamente: {style_of_writing}")


def set_project_index():
    get_project_guidelines = input("¿Quieres generar un proyecto para realizar? (s/n): ")
    while get_project_guidelines not in ["s", "n"]:
        get_project_guidelines = input("Por favor, introduce una opción válida: ")
    if get_project_guidelines == "s":
        generate_new_project_summary()
    else:
        load_project_index()


def load_project_index():
    global type_of_project
    print("Proyectos disponibles: ")
    list_of_project_guidelines = os.listdir(f"data/generated_index/{type_of_project}")
    for file_name in list_of_project_guidelines:
        print(file_name)
    project_guideline = input("Introduce el nombre de la guía del proyecto: ")
    while project_guideline not in list_of_project_guidelines:
        project_guideline = input("Por favor, introduce un nombre válido: ")
    load_project_guidelines_summary_from_json(project_guideline)


def generate_new_project_summary():
    global project_summary
    project_summary = input("Introduce el resumen del proyecto: ")
    while project_summary == "":
        project_summary = input("Por favor, introduce un resumen válido: ")
    project_summary_json = json.loads(gpt_index_generation(project_summary))
    save_project_summary_in_json(project_summary_json)


def save_project_summary_in_json(project_summary_json):
    global project_guideline_summary
    global project_name
    global type_of_project
    global index

    project_guideline_summary = project_summary_json["summary"]
    index = Chapter.chapters_from_json_array(project_summary_json["proposed_index"])
    if os.path.exists(f"data/generated_index/{type_of_project}/{project_name}.json"):
        os.remove(f"data/generated_index/{type_of_project}/{project_name}.json")
    with open(f"data/generated_index/{type_of_project}/{project_name}.json", "w") as outfile:
        json.dump(project_summary_json, outfile)


def load_project_guidelines_summary_from_json(filename):
    global project_guideline_summary
    global type_of_project
    global index
    with open(f"data/generated_index/{type_of_project}/{filename}", "r") as outfile:
        project_guideline_json = json.load(outfile)
    project_guideline_summary = project_guideline_json["summary"]
    index = Chapter.chapters_from_json_array(project_guideline_json["proposed_index"])
    print(f"Resumen del proyecto cargado correctamente: {project_guideline_summary} \n\n Índice: {index}")


async def main():
    select_project_type()
    set_style_of_writing()
    set_general_project_info()
    set_project_index()
    await generate_project()


if __name__ == "__main__":
    asyncio.run(main())
